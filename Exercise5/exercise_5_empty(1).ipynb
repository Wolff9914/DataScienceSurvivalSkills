{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1732116399842,
     "user": {
      "displayName": "Florian Gritsch",
      "userId": "15973176802866174028"
     },
     "user_tz": -60
    },
    "id": "K13_B9WCpEcE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjdX09ltpEcF"
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NUlrku2pEcG"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gZDtlI5HpEcG"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fPQZ_eebpEcG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   0       145   233    1        2      150      0      2.3      2   \n",
       "1   67    1   3       160   286    0        2      108      1      1.5      1   \n",
       "2   67    1   3       120   229    0        2      129      1      2.6      1   \n",
       "3   37    1   2       130   250    0        0      187      0      3.5      2   \n",
       "4   41    0   1       130   204    0        2      172      0      1.4      0   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     2       0  \n",
       "1   3     1       1  \n",
       "2   2     3       1  \n",
       "3   0     1       0  \n",
       "4   0     1       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv('Heart_disease_cleveland_new.csv')\n",
    "#TODO\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvci7HHzpEcH"
   },
   "source": [
    "https://www.kaggle.com/datasets/ritwikb3/heart-disease-cleveland/\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "### Task\n",
    "Visualize the dataset in a low-dimensional feature space (two dimensions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCc71wL-pEcH"
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRbm1JW4pEcH"
   },
   "outputs": [],
   "source": [
    "X_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhFMPUQHpEcH"
   },
   "outputs": [],
   "source": [
    "# apply PCA\n",
    "#TODO\n",
    "# plot the data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_heart contains class labels\n",
    "classes = np.unique(y_heart)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_heart_pca[y_heart == cls, 0],\n",
    "        X_heart_pca[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Heart Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCSlm_bMpEcI"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb88K8DupEcI"
   },
   "outputs": [],
   "source": [
    "#apply scaler\n",
    "#TODO\n",
    "X_heart_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hvpU2zzpEcJ"
   },
   "outputs": [],
   "source": [
    "# apply PCA\n",
    "#TODO\n",
    "\n",
    "# plot both\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_heart_pca[y_heart == cls, 0],\n",
    "        X_heart_pca[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('Without standardization')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_heart_pca_standardized[y_heart == cls, 0],\n",
    "        X_heart_pca_standardized[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('With standardization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofJjK_sHzVH3"
   },
   "outputs": [],
   "source": [
    "# Plot the explained variance ratio\n",
    "#TODO\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.7, align='center')\n",
    "plt.step(range(1, len(explained_variance_ratio) + 1), np.cumsum(explained_variance_ratio), where='mid', label='Cumulative Explained Variance')\n",
    "plt.xlabel('Principal Component Index')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.title('Explained Variance Ratio for Principal Components')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIdnftamJYCF"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Apply PCA for 3 components\n",
    "#TODO\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for cls in classes:\n",
    "    ax.scatter(\n",
    "        X_heart_pca_standardized[y_heart == cls, 0],\n",
    "        X_heart_pca_standardized[y_heart == cls, 1],\n",
    "        X_heart_pca_standardized[y_heart == cls, 2],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_zlabel('PCA 3')\n",
    "ax.set_title('3D PCA Plot with Standardization')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_c98X-KpEcJ"
   },
   "source": [
    "We can also calculate the PCA manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbJJsU1cpEcJ"
   },
   "outputs": [],
   "source": [
    "def get_cov_matrix(X):\n",
    "    #TODO\n",
    "\n",
    "def get_cov_matrix_np(X):\n",
    "    cov_matrix = np.cov(X.T)\n",
    "    return cov_matrix\n",
    "\n",
    "cov_mat = get_cov_matrix(X_heart)\n",
    "cov_mat_np = get_cov_matrix_np(X_heart)\n",
    "\n",
    "np.allclose(cov_mat, cov_mat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgngFgG9pEcK"
   },
   "outputs": [],
   "source": [
    "def get_eigen(cov_matrix):\n",
    "    #TODO\n",
    "\n",
    "eigen_values, eigen_vectors = get_eigen(cov_mat)\n",
    "print(eigen_values)\n",
    "print(eigen_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwYxVNaYpEcK"
   },
   "outputs": [],
   "source": [
    "def get_sorted_eig_pairs(eigen_values, eigen_vectors):\n",
    "    #TODO\n",
    "\n",
    "eigen_pairs = get_sorted_eig_pairs(eigen_values, eigen_vectors)\n",
    "print(eigen_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDa8PYe1pEcK"
   },
   "source": [
    "### Explained variance:\n",
    "- Statistical metric that measures the proportion of the total variance in a dataset that is captured or \"explained\" by a particular set of variables or components\n",
    "- Explained variance by each principal component is represented by its corresponding eigenvalue\n",
    "- Explained variance ratio for a principal component is the ratio of its eigenvalue to the sum of all eigenvalues\n",
    "- Provides insights into the importance of each principal component. Components with higher explained variance are more influential in describing the underlying structure of the data\n",
    "- A high cumulative explained variance suggests that the selected principal components effectively capture the variability in the data, allowing for meaningful dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UWlMBgtpEcK"
   },
   "outputs": [],
   "source": [
    "def get_explained_variance(eigen_values):\n",
    "    #TODO\n",
    "    total = sum(eigen_values)\n",
    "    #explained_variance 0 [(i/total)*100 for i in sorted(eigen_values,)]\n",
    "\n",
    "explained_variance = get_explained_variance(eigen_values)\n",
    "print(explained_variance)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, align='center')\n",
    "plt.step(range(1, len(explained_variance) + 1), np.cumsum(explained_variance), where='mid', label='Cumulative Explained Variance')\n",
    "plt.xlabel('Principal Component Index')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.title('Explained Variance Ratio for Principal Components')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dADRgU-vpEcL"
   },
   "outputs": [],
   "source": [
    "def get_projection_matrix(eigen_pairs, n_components):\n",
    "    projection_matrix = np.hstack([eigen_pairs[i][1].reshape(13, 1) for i in range(n_components)])\n",
    "    return projection_matrix\n",
    "\n",
    "projection_matrix = get_projection_matrix(eigen_pairs, 3)\n",
    "print(projection_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BNt650LpEcL"
   },
   "outputs": [],
   "source": [
    "def get_PCA(X, n_components):\n",
    "    #TODO\n",
    "\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy8g2zUbpEcM"
   },
   "outputs": [],
   "source": [
    "X_heart_pca_standardized = get_PCA(X_heart_standardized, 3)\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for cls in classes:\n",
    "    ax.scatter(\n",
    "        X_heart_pca_standardized[y_heart == cls, 0],\n",
    "        X_heart_pca_standardized[y_heart == cls, 1],\n",
    "        X_heart_pca_standardized[y_heart == cls, 2],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_zlabel('PCA 3')\n",
    "ax.set_title('3D PCA Plot with Standardization')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88vI4wvONeEz"
   },
   "source": [
    "###Lets plot in in a interactive code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c3fBTT9NH7D"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Prepare the data for Plotly\n",
    "data = pd.DataFrame({\n",
    "    'PCA 1': X_heart_pca_standardized[:, 0],\n",
    "    'PCA 2': X_heart_pca_standardized[:, 1],\n",
    "    'PCA 3': X_heart_pca_standardized[:, 2],\n",
    "    'Class': y_heart\n",
    "})\n",
    "\n",
    "# Create an interactive 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    data,\n",
    "    x='PCA 1',\n",
    "    y='PCA 2',\n",
    "    z='PCA 3',\n",
    "    color='Class',\n",
    "    title='3D PCA Plot with Standardization'\n",
    ")\n",
    "\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='PCA 1',\n",
    "    yaxis_title='PCA 2',\n",
    "    zaxis_title='PCA 3'\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSHgTl3RpEcM"
   },
   "source": [
    "### Use SVD for PCA instead of eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhOuN0AbOGlL"
   },
   "source": [
    "Singular Value Decomposition (SVD) is a fundamental matrix factorization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3r2UVtlpEcM"
   },
   "outputs": [],
   "source": [
    "def get_PCA_svd(X, n_components):\n",
    "    #TODO\n",
    "\n",
    "X_heart_pca = get_PCA_svd(X_heart, 2)\n",
    "X_heart_pca_standardized = get_PCA_svd(X_heart_standardized, 2)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_heart_pca[y_heart == cls, 0],\n",
    "        X_heart_pca[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('Without standardization')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_heart_pca_standardized[y_heart == cls, 0],\n",
    "        X_heart_pca_standardized[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('With standardization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlvUi5gPpEcM"
   },
   "source": [
    "## t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvGGZYvbpEcM"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naXm3dm1pEcN"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the TSNE class\n",
    "#TODO\n",
    "\n",
    "# Apply t-SNE to the data\n",
    "X_tsne = tsne.fit_transform(X_heart)\n",
    "X_tsne_standardized = tsne.fit_transform(X_heart_standardized)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_tsne[y_heart == cls, 0],\n",
    "        X_tsne[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('Without standardization')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "for cls in classes:\n",
    "    plt.scatter(\n",
    "        X_tsne_standardized[y_heart == cls, 0],\n",
    "        X_tsne_standardized[y_heart == cls, 1],\n",
    "        label=f'Class {cls}'\n",
    "    )\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('With standardization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9u97E6JdpEcN"
   },
   "source": [
    "# Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOc29K-WpEcN"
   },
   "source": [
    "We now look at the ages of all patients with and without heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq5i4HcipEcN"
   },
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgGvdpwdpEcO"
   },
   "outputs": [],
   "source": [
    "#plot boxplots\n",
    "#TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icrtYWUNpEcO"
   },
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# create dummy variables\n",
    "test = np.random.normal(0, 1, 1000)\n",
    "\n",
    "sm.qqplot(test, line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkqGxvBIpEcO"
   },
   "outputs": [],
   "source": [
    "# --> if the data is normally distributed, the points should be on the red line\n",
    "sm.qqplot(heart_disease[heart_disease['target'] == 0]['age'], line='s')\n",
    "plt.title('No disease')\n",
    "sm.qqplot(heart_disease[heart_disease['target'] == 1]['age'], line='s')\n",
    "plt.title('Disease')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gH3eccipEcO"
   },
   "source": [
    "### Assumptions:\n",
    "- Data is approximately normally distributed\n",
    "- The two groups are independent\n",
    "\n",
    "(if the data would not be normally distributed or sample sizes are too small, we could use, for example, the Mann-Whitney U test (non-parametric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysiE4dIrpEcO"
   },
   "outputs": [],
   "source": [
    "# H0: there is no difference in the mean age between patients with and without heart disease\n",
    "# H1: there is a difference in the mean age between patients with and without heart disease\n",
    "\n",
    "# perform a t-testst\n",
    "# --> we use the t-test for independent samples because we have two independent groups (patients with and without heart disease)\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "#TODO\n",
    "\n",
    "print('t-statistic: {}'.format(t_statistic))\n",
    "print('p-value: {}'.format(p_value))\n",
    "\n",
    "# check if significant\n",
    "if p_value < 0.05:\n",
    "    print('We reject the null hypothesis')\n",
    "else:\n",
    "    print('We fail to reject the null hypothesis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPKHP56TpEcP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
